# Deep Neural Networks from Scratch

This repository contains the code for building Deep Neural Networks (DNNs) from scratch using NumPy. The project includes the design and implementation of components for Multilayer Perceptron (MLP) and Convolutional Neural Network (CNN) architectures.

## Key Features
- Implemented forward and backward passes for various layers:
  - Fully Connected
  - Conv2D
  - GeLU activation
  - MaxPool
  - Dropout
- Utilized optimization techniques such as:
  - Stochastic Gradient Descent (SGD)
  - Adaptive Moment Estimation (ADAM)
- Incorporated regularization methods including L1 and L2 regularization, and weight decay.
- Applied cross-entropy loss for training the models.
